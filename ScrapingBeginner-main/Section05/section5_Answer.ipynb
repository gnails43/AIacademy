{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【第5回】BeautifulSoupの使い方③\n",
    "\n",
    "これまでの講義で、BeautifulSoupを使って以下のことができるようになりました。\n",
    "\n",
    "- 第3回目の講義 : **find()**を使って該当するタグ(例えば`<h2>`)から**1つだけ要素**を取り出す\n",
    "- 第4回目の講義 : **find_all()**を使って該当するタグ(例えば`<h2>`)から**すべての要素**を取り出す\n",
    "\n",
    "今回の講義では、クラスを指定して`find_all()`を使うことで、自分が欲しい情報をピンポイントで取得していきたいと思います。\n",
    "\n",
    "また、今回の講義では演習も付けています。演習を通して大事なことをお伝えしていきますので、ぜひ最後まで聴いていただけると嬉しいです！\n",
    "\n",
    "\n",
    "*※動画の感想を、僕のTwitterにメンションしてツイートしていただけると嬉しいです（ ;  ; ）！*\n",
    "\n",
    "Twitter : [@hayatasuuu](https://twitter.com/hayatasuuu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラスを指定して情報を取得する\n",
    "\n",
    "今回のレクチャーでもPythonの公式ページを使っていきます。\n",
    "\n",
    "前回は、`find_all()`を使ってすべての`<h2>`タグを取得しましたが、今回はさらに条件を絞ってデータ抽出できるようになりましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート\n",
    "\n",
    "まずはライブラリのインポートをします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP1 : RequestsでHTMLを取得する\n",
    "\n",
    "こちらも今までどおりですね。`Requests`を使って、Python公式ページへアクセスしていきます。\n",
    "\n",
    "https://www.python.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数urlに、Python公式ページのURLを入れる\n",
    "url = 'https://www.python.org/'\n",
    "\n",
    "# URLにアクセスした結果を、変数rに代入する\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP2 : 取得したHTMLを解析する\n",
    "\n",
    "アクセス結果からテキスト情報を取得して、`BeautifulSoup`でHTMLを解析しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoupでHTMLを解析する\n",
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あとは、クラスを指定して情報を取得するだけですね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスを指定して情報を取得する\n",
    "\n",
    "今回は、今まで扱っていた`<h2>`タグではなく、`<span>`タグの情報を取得していきたいと思います。\n",
    "\n",
    "Python公式ページには、非常にたくさんの`<span>`タグが使われており、クラス指定の効果を体感するには持ってこいだからです。\n",
    "\n",
    "<br>\n",
    "\n",
    "というわけで、まずはいつも通りに`find_all()`を使って`<span>`タグを取得してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<span aria-hidden=\"true\" class=\"icon-arrow-down\"><span>▼</span></span>,\n",
       " <span>▼</span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-arrow-up\"><span>▲</span></span>,\n",
       " <span>▲</span>,\n",
       " <span class=\"menu-icon\">≡</span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-search\"></span>,\n",
       " <span class=\"breaker\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-facebook\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-twitter\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-freenode\"></span>,\n",
       " <span data-html-include=\"/authenticated\"></span>,\n",
       " <span class=\"message\">Launch Interactive Shell</span>,\n",
       " <span class=\"comment\"># Python 3: Fibonacci series up to n</span>,\n",
       " <span class=\"output\">0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span>,\n",
       " <span class=\"comment\"># Python 3: List comprehensions</span>,\n",
       " <span class=\"output\">['BANANA', 'APPLE', 'LIME']</span>,\n",
       " <span class=\"comment\"># List and the enumerate function</span>,\n",
       " <span class=\"output\">[(0, 'Banana'), (1, 'Apple'), (2, 'Lime')]</span>,\n",
       " <span class=\"comment\"># Python 3: Simple arithmetic</span>,\n",
       " <span class=\"output\">0.5</span>,\n",
       " <span class=\"output\">8</span>,\n",
       " <span class=\"comment\"># classic division returns a float</span>,\n",
       " <span class=\"output\">5.666666666666667</span>,\n",
       " <span class=\"comment\"># floor division</span>,\n",
       " <span class=\"output\">5</span>,\n",
       " <span class=\"comment\"># Python 3: Simple output (with Unicode)</span>,\n",
       " <span class=\"output\">Hello, I'm Python!</span>,\n",
       " <span class=\"comment\"># Input, assignment</span>,\n",
       " <span class=\"output\">What is your name?\n",
       " Python\n",
       " Hi, Python.</span>,\n",
       " <span class=\"comment\"># For loop on a list</span>,\n",
       " <span class=\"output\">The product is: 384</span>,\n",
       " <span class=\"breaker\"></span>,\n",
       " <span class=\"notification-bar__icon\">\n",
       " <i aria-hidden=\"true\" class=\"fa fa-chart-line\"></i>\n",
       " </span>,\n",
       " <span class=\"notification-bar__message\">Join the official 2020 Python Developers Survey   <a class=\"button button--dark button--small button--primary\" href=\"https://surveys.jetbrains.com/s3/c8-python-developers-survey-2020\" rel=\"noopener\" style=\"color: #606060; border-color: #006dad; background-color: #006dad;\" target=\"_blank\">Start the survey!</a>\n",
       " </span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-get-started\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-download\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-documentation\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-jobs\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-news\"></span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-calendar\"></span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-success-stories\"></span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-python\"></span>,\n",
       " <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://www.djangoproject.com/\">Django</a>, <a class=\"tag\" href=\"http://www.pylonsproject.org/\">Pyramid</a>, <a class=\"tag\" href=\"http://bottlepy.org\">Bottle</a>, <a class=\"tag\" href=\"http://tornadoweb.org\">Tornado</a>, <a class=\"tag\" href=\"http://flask.pocoo.org/\">Flask</a>, <a class=\"tag\" href=\"http://www.web2py.com/\">web2py</a></span>,\n",
       " <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://wiki.python.org/moin/TkInter\">tkInter</a>, <a class=\"tag\" href=\"https://wiki.gnome.org/Projects/PyGObject\">PyGObject</a>, <a class=\"tag\" href=\"http://www.riverbankcomputing.co.uk/software/pyqt/intro\">PyQt</a>, <a class=\"tag\" href=\"https://wiki.qt.io/PySide\">PySide</a>, <a class=\"tag\" href=\"https://kivy.org/\">Kivy</a>, <a class=\"tag\" href=\"http://www.wxpython.org/\">wxPython</a></span>,\n",
       " <span class=\"tag-wrapper\">\n",
       " <a class=\"tag\" href=\"http://www.scipy.org\">SciPy</a>, <a class=\"tag\" href=\"http://pandas.pydata.org/\">Pandas</a>, <a class=\"tag\" href=\"http://ipython.org\">IPython</a></span>,\n",
       " <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://buildbot.net/\">Buildbot</a>, <a class=\"tag\" href=\"http://trac.edgewall.org/\">Trac</a>, <a class=\"tag\" href=\"http://roundup.sourceforge.net/\">Roundup</a></span>,\n",
       " <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://www.ansible.com\">Ansible</a>, <a class=\"tag\" href=\"http://www.saltstack.com\">Salt</a>, <a class=\"tag\" href=\"https://www.openstack.org\">OpenStack</a></span>,\n",
       " <span class=\"prompt\">&gt;&gt;&gt;</span>,\n",
       " <span class=\"say-no-more\"> (PEPs)</span>,\n",
       " <span class=\"say-no-more\"> is discussed here.</span>,\n",
       " <span class=\"icon-feed\"></span>,\n",
       " <span class=\"prompt\">&gt;&gt;&gt;</span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-arrow-up\"><span>▲</span></span>,\n",
       " <span>▲</span>,\n",
       " <span aria-hidden=\"true\" class=\"icon-arrow-up\"><span>▲</span></span>,\n",
       " <span>▲</span>,\n",
       " <span class=\"say-no-more\">General</span>,\n",
       " <span class=\"say-no-more\">Initiatives</span>,\n",
       " <span class=\"python-status-indicator-default\" id=\"python-status-indicator\"></span>,\n",
       " <span class=\"pre\">Copyright ©2001-2020.</span>,\n",
       " <span class=\"pre\"><a href=\"/psf-landing/\">Python Software Foundation</a></span>,\n",
       " <span class=\"pre\"><a href=\"/about/legal/\">Legal Statements</a></span>,\n",
       " <span class=\"pre\"><a href=\"/privacy/\">Privacy Policy</a></span>,\n",
       " <span class=\"pre\"><a href=\"/psf/sponsorship/sponsors/#heroku\">Powered by Heroku</a></span>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spanタグの数を確認する\n",
    "print(len(soup.find_all('span')))\n",
    "\n",
    "# Python公式ページで、すべてのspanタグを確認\n",
    "soup.find_all('span')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果を確認してみると、全部で74個の`<span>`があることが分かりました。\n",
    "\n",
    "これらすべての情報が欲しいという機会はあまりなく、やはり「特定の`<span>`タグの情報が欲しい」と思う機会が多いはずです。\n",
    "\n",
    "今回は、たとえば「`say-no-more`というクラス名が付いているテキストだけ取得する」ということを考えていきましょう。\n",
    "\n",
    "<br>\n",
    "\n",
    "クラスを指定する方法は非常にカンタンで、`find_all()`の引数に`class_`を追加してあげるだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\"> (PEPs)</span>,\n",
       " <span class=\"say-no-more\"> is discussed here.</span>,\n",
       " <span class=\"say-no-more\">General</span>,\n",
       " <span class=\"say-no-more\">Initiatives</span>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say-no-moreクラスを持つspanタグをすべて取得する\n",
    "soup.find_all('span', class_='say-no-more')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得結果を見てみると、`say-no-more`クラスを持つ`<span>`タグだけ取得できています。\n",
    "\n",
    "このように、該当するクラスを指定してタグを取得するときは、`class_`を使ってあげます。\n",
    "\n",
    "*※`class`ではなく`class_`が採用されている理由は、Pythonの予約語で`class`が存在するからです。予約語というのは、Pythonであらかじめ使われている名前です！*\n",
    "\n",
    "なので、`BeautifulSoup`ではアンダースコアがついたクラスを使ってあげます。\n",
    "\n",
    "<br>\n",
    "\n",
    "もしアンダースコアが付かない形でクラスを指定したい場合、以下のように辞書の形で書くことも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\"> (PEPs)</span>,\n",
       " <span class=\"say-no-more\"> is discussed here.</span>,\n",
       " <span class=\"say-no-more\">General</span>,\n",
       " <span class=\"say-no-more\">Initiatives</span>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 辞書の形でsay-no-moreをクラスに持つspanタグを取得する\n",
    "soup.find_all('span', {'class': 'say-no-more'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正確には引数`attrs`に渡しているので、`soup.find_all('span', attrs={'class': 'say-no-more'})`ですが、これは省略して問題ないです。\n",
    "\n",
    "<br>\n",
    "\n",
    "さらに、複数のクラスを指定することも可能です。\n",
    "\n",
    "今回は`say-no-more`だけでなく、`message`クラスも一緒に取得していきましょう。\n",
    "\n",
    "複数のクラスを指定するには、リストの形で引数に渡してあげます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"message\">Launch Interactive Shell</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\">2020-</span>,\n",
       " <span class=\"say-no-more\"> (PEPs)</span>,\n",
       " <span class=\"say-no-more\"> is discussed here.</span>,\n",
       " <span class=\"say-no-more\">General</span>,\n",
       " <span class=\"say-no-more\">Initiatives</span>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# messageとsay-no-moreをクラスに持つspanタグを取得する\n",
    "soup.find_all('span', class_=['say-no-more', 'message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こうですね。\n",
    "\n",
    "これで複数のクラスを指定して`<span>`タグの情報を取得できるようになりました。\n",
    "\n",
    "<br>\n",
    "\n",
    "ここまで習得した内容を使っても、かなりできることが増えましたね！\n",
    "\n",
    "とは言っても、やはり知識はアウトプットしないと定着しないので、演習問題をやってみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習\n",
    "\n",
    "[テックダイアリー(僕のブログ)](https://tech-diary.net)の以下の記事で、すべての見出し(`<h2>`と`<h3>`)を取得して、リスト形式で保存しましょう。\n",
    "\n",
    "https://tech-diary.net/python-scraping-books/\n",
    "\n",
    "<hr>\n",
    "\n",
    "▼完成イメージ\n",
    "```\n",
    "['【厳選4冊】Webスクレイピング(Python)でおすすめの本【実務OK】',\n",
    " 'おすすめ① : Python2年生 スクレイピングのしくみ 体験してわかる！会話でまなべる！',\n",
    " 'おすすめ② : Pythonクローリング&スクレイピング[増補改訂版]',\n",
    " 'おすすめ③ : Pythonスクレイピングの基本と実践 データサイエンティストのためのWebデータ収集術',\n",
    " 'おすすめ④ : PythonによるWebスクレイピング 第2版',\n",
    " '【Webスクレイピング学習】Pythonとセットで学ぶべきこと3つ',\n",
    " '学ぶべきこと① : HTML, CSS',\n",
    " '学ぶべきこと② : JavaScript',\n",
    " '学ぶべきこと③ : Web技術の知識',\n",
    " 'まずは無料でPythonとスクレイピングを学ぼう【本より分かりやすい】']\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "*※できれば1回のリクエストで情報取得していただけると嬉しいです（ ;  ; ）*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://tech-diary.net/python-scraping-books/'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2><span id=\"4WebPythonOK\">【厳選4冊】Webスクレイピング(Python)でおすすめの本【実務OK】</span></h2>,\n",
       " <h3><span id=\"_Python2\">おすすめ① : Python2年生 スクレイピングのしくみ 体験してわかる！会話でまなべる！</span></h3>,\n",
       " <h3><span id=\"_Python\">おすすめ② : Pythonクローリング&amp;スクレイピング[増補改訂版]</span></h3>,\n",
       " <h3><span id=\"_Python_Web\">おすすめ③ : Pythonスクレイピングの基本と実践 データサイエンティストのためのWebデータ収集術</span></h3>,\n",
       " <h3><span id=\"_PythonWeb_2\">おすすめ④ : PythonによるWebスクレイピング 第2版</span></h3>,\n",
       " <h2><span id=\"WebPython3\">【Webスクレイピング学習】Pythonとセットで学ぶべきこと3つ</span></h2>,\n",
       " <h3><span id=\"_HTML_CSS\">学ぶべきこと① : HTML, CSS</span></h3>,\n",
       " <h3><span id=\"_JavaScript\">学ぶべきこと② : JavaScript</span></h3>,\n",
       " <h3><span id=\"_Web\">学ぶべきこと③ : Web技術の知識</span></h3>,\n",
       " <h2><span id=\"Python\">まずは無料でPythonとスクレイピングを学ぼう【本より分かりやすい】</span></h2>,\n",
       " <h2 class=\"post-list-title entry-title\" itemprop=\"headline\">PythonでスクレイピングしたデータをCSVに保存する方法【3STEPで解説】</h2>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(['h2', 'h3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_2_and_3 = [tag.text for tag in soup.find_all(['h2', 'h3'])]\n",
    "# header_2_and_3 = list(map(lambda s: s.text, soup.find_all(['h2', 'h3'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*※答えのソースコードには書いていますが、以下のようにリスト内包表記ではなく、map()を使うのがベストです！実行時間を計測してみると、map()を使った方が処理が早いことが分かります！*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.29 ms, sys: 107 µs, total: 7.4 ms\n",
      "Wall time: 7.32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "header_2_and_3 = [tag.text for tag in soup.find_all(['h2', 'h3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.23 ms, sys: 84 µs, total: 5.31 ms\n",
      "Wall time: 5.25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "header_2_and_3 = list(map(lambda s: s.text, soup.find_all(['h2', 'h3'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['【厳選4冊】Webスクレイピング(Python)でおすすめの本【実務OK】',\n",
       " 'おすすめ① : Python2年生 スクレイピングのしくみ 体験してわかる！会話でまなべる！',\n",
       " 'おすすめ② : Pythonクローリング&スクレイピング[増補改訂版]',\n",
       " 'おすすめ③ : Pythonスクレイピングの基本と実践 データサイエンティストのためのWebデータ収集術',\n",
       " 'おすすめ④ : PythonによるWebスクレイピング 第2版',\n",
       " '【Webスクレイピング学習】Pythonとセットで学ぶべきこと3つ',\n",
       " '学ぶべきこと① : HTML, CSS',\n",
       " '学ぶべきこと② : JavaScript',\n",
       " '学ぶべきこと③ : Web技術の知識',\n",
       " 'まずは無料でPythonとスクレイピングを学ぼう【本より分かりやすい】',\n",
       " 'PythonでスクレイピングしたデータをCSVに保存する方法【3STEPで解説】']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_2_and_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足\n",
    "\n",
    "今回の演習で取得したヘッダーの中には、1つ余計なものが含まれています。\n",
    "\n",
    "実際に記事を見ていただけると分かりますが、関連記事の情報まで取得してしまっています。\n",
    "\n",
    "<br>\n",
    "\n",
    "関連記事の情報は、「記事の見出し(`<h2>`と`<h3>`)を取得する」が目的だったとき、ノイズになってしまいます。\n",
    "\n",
    "これを解決するには、以下の方法があります。\n",
    "\n",
    "- 取得する範囲を狭くする\n",
    "- 該当する要素を削除する\n",
    "\n",
    "これらも合わせて見ていきましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得する範囲を狭くする\n",
    "\n",
    "「`Requests`で取得したHTML全体に対して」ではなく、「記事の本文に対して」見出しタグを取得すれば問題を解決できます。\n",
    "\n",
    "今まで`soup.find()`のように、`find()`を一回しか使いませんでしたが、実は**何度も使うことが可能**です。\n",
    "\n",
    "<br>\n",
    "\n",
    "このことを利用すると、記事の本文に対してすべての見出しタグを取得するには、以下のように書くことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2><span id=\"4WebPythonOK\">【厳選4冊】Webスクレイピング(Python)でおすすめの本【実務OK】</span></h2>,\n",
       " <h3><span id=\"_Python2\">おすすめ① : Python2年生 スクレイピングのしくみ 体験してわかる！会話でまなべる！</span></h3>,\n",
       " <h3><span id=\"_Python\">おすすめ② : Pythonクローリング&amp;スクレイピング[増補改訂版]</span></h3>,\n",
       " <h3><span id=\"_Python_Web\">おすすめ③ : Pythonスクレイピングの基本と実践 データサイエンティストのためのWebデータ収集術</span></h3>,\n",
       " <h3><span id=\"_PythonWeb_2\">おすすめ④ : PythonによるWebスクレイピング 第2版</span></h3>,\n",
       " <h2><span id=\"WebPython3\">【Webスクレイピング学習】Pythonとセットで学ぶべきこと3つ</span></h2>,\n",
       " <h3><span id=\"_HTML_CSS\">学ぶべきこと① : HTML, CSS</span></h3>,\n",
       " <h3><span id=\"_JavaScript\">学ぶべきこと② : JavaScript</span></h3>,\n",
       " <h3><span id=\"_Web\">学ぶべきこと③ : Web技術の知識</span></h3>,\n",
       " <h2><span id=\"Python\">まずは無料でPythonとスクレイピングを学ぼう【本より分かりやすい】</span></h2>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 記事本文の部分を指定してから見出しタグを取得する\n",
    "soup.find('article').find_all(['h2', 'h3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほどまでは、余計な`<h2>`タグが含まれていましたが、今回は記事の本文から見出しを取得しているのでノイズ削除できました。\n",
    "\n",
    "このように、どんどん範囲を狭めていって情報抽出する方法は、非常によく使います。\n",
    "\n",
    "<br>\n",
    "\n",
    "また記事の本文から、他に取得したい部分がある可能性が高いので、以下のようにいったん変数に入れてあげるのも良いですね。\n",
    "\n",
    "*※僕自身、複数回使う部分を変数に入れて、その後で細かい部分を取りにいくことが多いです！*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2><span id=\"4WebPythonOK\">【厳選4冊】Webスクレイピング(Python)でおすすめの本【実務OK】</span></h2>,\n",
       " <h3><span id=\"_Python2\">おすすめ① : Python2年生 スクレイピングのしくみ 体験してわかる！会話でまなべる！</span></h3>,\n",
       " <h3><span id=\"_Python\">おすすめ② : Pythonクローリング&amp;スクレイピング[増補改訂版]</span></h3>,\n",
       " <h3><span id=\"_Python_Web\">おすすめ③ : Pythonスクレイピングの基本と実践 データサイエンティストのためのWebデータ収集術</span></h3>,\n",
       " <h3><span id=\"_PythonWeb_2\">おすすめ④ : PythonによるWebスクレイピング 第2版</span></h3>,\n",
       " <h2><span id=\"WebPython3\">【Webスクレイピング学習】Pythonとセットで学ぶべきこと3つ</span></h2>,\n",
       " <h3><span id=\"_HTML_CSS\">学ぶべきこと① : HTML, CSS</span></h3>,\n",
       " <h3><span id=\"_JavaScript\">学ぶべきこと② : JavaScript</span></h3>,\n",
       " <h3><span id=\"_Web\">学ぶべきこと③ : Web技術の知識</span></h3>,\n",
       " <h2><span id=\"Python\">まずは無料でPythonとスクレイピングを学ぼう【本より分かりやすい】</span></h2>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 変数bodyに、記事本文を入れておく\n",
    "body = soup.find('article')\n",
    "\n",
    "# bodyから見出しをすべて取得する\n",
    "body.find_all(['h2', 'h3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように書いておけば、何回も`soup.find('article')`を書かずに済みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 該当する要素を削除する\n",
    "\n",
    "もうひとつは、該当する要素を削除する方法です。\n",
    "\n",
    "この方法では`find()`を使って要素を特定したあとで、`extract()`を使ってあげます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "削除前の見出し数： 11\n",
      "削除後の見出し数： 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<h2><span id=\"4WebPythonOK\">【厳選4冊】Webスクレイピング(Python)でおすすめの本【実務OK】</span></h2>,\n",
       " <h3><span id=\"_Python2\">おすすめ① : Python2年生 スクレイピングのしくみ 体験してわかる！会話でまなべる！</span></h3>,\n",
       " <h3><span id=\"_Python\">おすすめ② : Pythonクローリング&amp;スクレイピング[増補改訂版]</span></h3>,\n",
       " <h3><span id=\"_Python_Web\">おすすめ③ : Pythonスクレイピングの基本と実践 データサイエンティストのためのWebデータ収集術</span></h3>,\n",
       " <h3><span id=\"_PythonWeb_2\">おすすめ④ : PythonによるWebスクレイピング 第2版</span></h3>,\n",
       " <h2><span id=\"WebPython3\">【Webスクレイピング学習】Pythonとセットで学ぶべきこと3つ</span></h2>,\n",
       " <h3><span id=\"_HTML_CSS\">学ぶべきこと① : HTML, CSS</span></h3>,\n",
       " <h3><span id=\"_JavaScript\">学ぶべきこと② : JavaScript</span></h3>,\n",
       " <h3><span id=\"_Web\">学ぶべきこと③ : Web技術の知識</span></h3>,\n",
       " <h2><span id=\"Python\">まずは無料でPythonとスクレイピングを学ぼう【本より分かりやすい】</span></h2>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 削除前の見出し数を確認\n",
    "print('削除前の見出し数：', len(soup.find_all(['h2', 'h3'])))\n",
    "\n",
    "# 該当する要素を削除する\n",
    "soup.find('h2', {'class': 'post-list-title'}).extract()\n",
    "\n",
    "# 削除後の見出し数を確認\n",
    "print('削除後の見出し数：', len(soup.find_all(['h2', 'h3'])))\n",
    "\n",
    "# 見出しの中身を確認\n",
    "soup.find_all(['h2', 'h3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`extrace()`を使うことで、ノイズになっていた見出しを削除できていることが分かるかと思います。\n",
    "\n",
    "これでも必要としていたデータ抽出ができていますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### おすすめのデータ抽出方法\n",
    "\n",
    "取得したいデータの抽出方法を2つ紹介してきました。\n",
    "\n",
    "- 取得する範囲を狭くする\n",
    "- 該当する要素を削除する\n",
    "\n",
    "2つ紹介したところで「どちらの方が良いのか」ですが、可能なかぎり「取得する範囲を狭くする」ことをオススメします。\n",
    "\n",
    "その理由は「該当する要素を削除する」だと、破壊的な方法になってしまうからです。\n",
    "\n",
    "<br>\n",
    "\n",
    "破壊的な方法というのは、取得してきたデータ(`soup`)の中身が変わってしまうということです。\n",
    "\n",
    "`extract()`を一度使ってしまうと`soup`の中から消えてしまうので、逆に「関連記事を取得したいな...」と思ったとき、その要素を取得できなくなります。\n",
    "\n",
    "仮に取得したい思ったときは、`requests.get()`を使って、HTMLの情報を取得し直す必要が出てきてしまいます。\n",
    "\n",
    "<br>\n",
    "\n",
    "そうすると、何回も相手方のWebサイトにアクセスすることになってしまうので、できれば取得したデータを変更しないで欲しいデータを抽出できる「取得する範囲を狭くする」方法を選びましょう！\n",
    "\n",
    "<br>\n",
    "\n",
    "というわけで、今回はクラス指定して情報を取得する方法と、さらには絞り込みをかける方法まで学習していきました。\n",
    "\n",
    "次回は今までの集大成を込めて、不動産のホームページから情報を抽出していきたいと思います。\n",
    "\n",
    "次回の内容が理解できると、JavaScriptが使われていないWebページであれば、自由自在に情報を取得できるようになります。\n",
    "\n",
    "一緒に頑張っていきましょう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
